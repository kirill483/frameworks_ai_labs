# AI-ML_MAI

## Лабораторные работы по прикладным системам и фреймворкам искусственного интеллекта

### МАИ | 4 курс | 7 семестр

**Выполнил студент:** Слетюрин Кирилл Сергеевич

**Группа:** М8О-408Б-22

## Наборы данных:

1. Задача классификации — cancer-risk-factors.csv, [Ссылка на датасет](https://www.kaggle.com/datasets/tarekmasryo/cancer-risk-factors-dataset)

**Описание:** Компактный и стандартизированный набор данных, изучающий влияние образа жизни, окружающей среды и генетических факторов на пять распространенных типов рака.

**Реальная практическая задача:** Прогнозирование разных типов рака в зависимости от жизненных условий поможет определить какие конкретные типы рака стоит проверить человеку.

2. Задача регрессии — Paris_housing_data.csv, [Ссылка на датасет](https://www.kaggle.com/datasets/mssmartypants/paris-housing-price-prediction/code)

**Описание:** Этот набор данных исследует, как ежедневные цифровые привычки, включая использование социальных сетей, время, проведенное за экраном, и воздействие уведомлений, связаны с индивидуальной продуктивностью.

**Реальная практическая задача:** Прогнозирование продуктивности  в зависимости от цифровых привычек поможет понять от каких цифровых привычек стоит отказаться, а каких наоборот придерживаться. Также можно узнавать цифровые привычки у соискателей/абитуриентов и в зависимости от полученных данных решать вопрос о приеме на работу/ в институт.  


## Обоснование выбора метрик для оценки моделей

## **Для классификации:**

### **1. Accuracy (Точность)**

**Что измеряет:** Долю правильных предсказаний среди всех предсказаний

**Формула:** (TP + TN) / (TP + TN + FP + FN)

**Выбор обоснован:** Базовая метрика для общей оценки модели.

### **2. Precision (Точность)**

**Что измеряет:** Долю истинно положительных случаев среди всех случаев, классифицированных как положительные

**Формула:** TP / (TP + FP)

**Выбор обоснован:** Критически важна для медицинской диагностики, так как минимизирует ложные положительные результаты (неправильные диагнозы рака), которые могут вызвать ненужную панику и дополнительные обследования.

### **3. Recall (Полнота)**

**Что измеряет:** Долю истинно положительных случаев среди всех реальных положительных случаев

**Формула:** TP / (TP + FN)


**Выбор обоснован:** Особенно важна для скрининга рака, так как минимизирует ложноотрицательные результаты (пропущенные случаи рака). В медицине лучше ошибиться в сторону дополнительной проверки, чем пропустить заболевание.

### **4. F1-Score (F-мера)**

**Что измеряет:** Гармоническое среднее между Precision и Recall

**Формула:** 2 × (Precision × Recall) / (Precision + Recall)

**Выбор обоснован:** Основная метрика для несбалансированных данных. 

## **Для регрессии:**

### **1. MSE (Mean Squared Error)**

**Что измеряет:** Среднеквадратичную ошибку предсказаний

**Формула:** Σ(yᵢ - ŷᵢ)² / n

**Выбор обоснован:** Основная метрика для регрессии. Сильнее штрафует за большие ошибки.

### **2. R² (Коэффициент детерминации)**

**Что измеряет:** Долю дисперсии зависимой переменной, объясненную моделью

**Формула:** 1 - (Σ(yᵢ - ŷᵢ)² / Σ(yᵢ - ȳ)²)

**Выбор обоснован:** Позволяет оценить, насколько хорошо модель объясняет данные по сравнению с простым средним. Значения ближе к 1 указывают на хорошее соответствие модели данным.



## Результаты 

## Sklearn:

### Классификация

Результаты для каждой модели sklearn до применения улучшенного безлайна:

1. KNN
    - F1-Score: 0.57
    - Accuracy: 0.58
    - Precision: 0.58      
    - Recall: 0.58
2. Логистическая регрессия
    - F1-Score: 0.72
    - Accuracy: 0.725
    - Precision: 0.72      
    - Recall: 0.72      
3. Решающее дерево
    - F1-Score: 0.59 
    - Accuracy:  0.5875
    - Precision: 0.60      
    - Recall: 0.59
4. Случайный лес
    - F1-Score: 0.78
    - Accuracy: 0.7825
    - Precision: 0.78      
    - Recall: 0.78
5. Градиентный бустинг
    - F1-Score: 0.77
    - Accuracy: 0.77
    - Precision: 0.77      
    - Recall: 0.77      

Результаты для каждой модели sklearn после применения улучшенного безлайна:

1. KNN
    - F1-Score: 0.69       
    - Accuracy: 0.705
    - Precision: 0.70           
    - Recall: 0.70      
2. Логистическая регрессия
    - F1-Score: 0.75       
    - Accuracy: 0.75
    - Precision: 0.75          
    - Recall: 0.75          
3. Решающее дерево
    - F1-Score: 0.68       
    - Accuracy:  0.68
    - Precision: 0.68                  
    - Recall: 0.68      
4. Случайный лес
    - F1-Score: 0.77       
    - Accuracy: 0.775
    - Precision: 0.77            
    - Recall: 0.78      
5. Градиентный бустинг
    - F1-Score: 0.77       
    - Accuracy: 0.7675
    - Precision: 0.76            
    - Recall: 0.77   

### Регрессия

Результаты для каждой модели sklearn до применения улучшенного безлайна:

1. KNN
    - MSE: 2.4292999887798516
    - R²: 0.2809548955036979
2. Линейная регрессия
    - MSE: 0.2711304927974215
    - R²: 0.9197484648145187
3. Решающее дерево
    - MSE: 0.5353353179748289
    - R²: 0.8415468482971886
4. Случайный лес
    - MSE: 0.2737884532538143
    - R²: 0.9189617388181652
5. Градиентный бустинг
    - MSE: 0.28539205646851157
    - R²: 0.9155272045389155


Результаты для каждой модели sklearn после применения улучшенного безлайна:

1. KNN
    - MSE: 1.6356877163619854
    - R²: 0.5158550815597089
2. Линейная регрессия
    - MSE: 0.27361716448797724
    - R²: 0.9190124383402907
3. Решающее дерево
    - MSE: 0.3209938715659406
    - R²: 0.904989473103842
4. Случайный лес
    - MSE: 0.5175954566189371
    - R²: 0.8467976450375302
5. Градиентный бустинг
    - MSE: 0.2658900430240416
    - R²: 0.9212995782102751

## Собственная имплементация:

### Классификация

Результаты для каждой собственной модели до применения улучшенного безлайна:

1. KNN
    - F1-Score: 0.55       
    - Accuracy: 0.555
    - Precision: 0.55      
    - Recall: 0.56      
2. Логистическая регрессия
    - F1-Score: 0.53       
    - Accuracy: 0.595
    - Precision: 0.71      
    - Recall: 0.59      
3. Решающее дерево
    - F1-Score: 0.60       
    - Accuracy: 0.595
    - Precision: 0.61      
    - Recall:0.59      
4. Случайный лес
    - F1-Score: 0.50       
    - Accuracy: 0.525       
    - Precision: 0.50      
    - Recall: 0.53      
5. Градиентный бустинг
    - F1-Score: 0.75       
    - Accuracy: 0.7525
    - Precision: 0.76      
    - Recall: 0.75      


Результаты для каждой собственной модели после применения улучшенного безлайна:

1. KNN
    - F1-Score: 0.69                     
    - Accuracy: 0.705
    - Precision: 0.70         
    - Recall: 0.70                
2. Логистическая регрессия
    - F1-Score: 0.69             
    - Accuracy: 0.7125
    - Precision: 0.71           
    - Recall: 0.71            
3. Решающее дерево
    - F1-Score: 0.69             
    - Accuracy: 0.685
    - Precision: 0.69    
    - Recall: 0.69            
4. Случайный лес
    - F1-Score: 0.78              
    - Accuracy: 0.535       
    - Precision: 0.78           
    - Recall: 0.78            
5. Градиентный бустинг
    - F1-Score: 0.75            
    - Accuracy: 0.755
    - Precision: 0.75     
    - Recall: 0.76                 


### Регрессия

Результаты для каждой собственной модели до применения улучшенного безлайна:

1. KNN
    - MSE: 2.383604302591147
    - R^2: 0.29448029771929274
2. Линейная регрессия
    - MSE: 0.27139987082883477
    - R^2: 0.9196687319879261
3. Решающее дерево
    - MSE: 0.5466626356213844
    - R^2: 0.8381940913966622
4. Случайный лес
    - MSE: 1.4455464412472652
    - R^2: 0.5721347315269383
5. Градиентный бустинг
    - MSE: 0.26457072928391306
    - R^2: 0.9216900800381743

Результаты для каждой собственной модели после применения улучшенного безлайна:

1. KNN
    - MSE: 0.6859945121523893
    - R^2: 0.7969534442214972
2. Линейная регрессия
    - MSE: 0.27139987082884526
    - R^2: 0.919668731987923
3. Решающее дерево
    - MSE: 0.3347494828512464
    - R^2: 0.9009179689669565
4. Случайный лес
    - MSE: 1.3056813058635777
    - R^2: 0.6135332172437497
5. Градиентный бустинг
    - MSE:  0.28002477379605567
    - R^2: 0.9171158590269993


## Выводы 


Анализ показывает, что случайный лес демонстрирует наилучшие результаты как в бейзлайне (F1-Score: 0.78), так и после улучшений. Интересно, что улучшенный бейзлайн принес значительный прирост качества для KNN (+0.12 по F1-Score), что ожидаемо, учитывая чувствительность этого алгоритма к масштабированию данных. Однако для некоторых моделей, таких как случайный лес и градиентный бустинг, улучшения дали минимальный эффект или даже небольшое ухудшение, что может свидетельствовать о переобучении или неоптимальном подборе гиперпараметров.


Сравнение scikit-learn и собственных реализаций выявляет значительный разрыв в качестве. Особенно заметно это для логистической регрессии (разница 0.19 по F1-Score) и случайного леса (разница 0.28). Это указывает на важность оптимизаций и тонких деталей реализации в промышленных библиотеках. При этом собственный градиентный бустинг показал сопоставимые с scikit-learn результаты, что говорит о качественной реализации этого алгоритма.


В задаче регрессии линейная регрессия демонстрирует выдающиеся результаты (R²: 0.919), что свидетельствует о сильной линейной зависимости в данных. Улучшенный бейзлайн особенно помог KNN (увеличение R² с 0.28 до 0.52), но ухудшил показатели случайного леса. Собственная реализация линейной регрессии практически идентична scikit-learn, что подтверждает корректность математической реализации, в то время как более сложные алгоритмы, такие как случайный лес, требуют более тщательной оптимизации.


Градиентный бустинг показывает стабильно высокие результаты в обеих реализациях, подтверждая свою эффективность для данного датасета. Примечательно, что после улучшений некоторые метрики ухудшились, что может указывать на необходимость более тонкой настройки препроцессинга.
